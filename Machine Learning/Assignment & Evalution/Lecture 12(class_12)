{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b030c85",
   "metadata": {},
   "source": [
    "# Classification implementation continued"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75fba0f",
   "metadata": {},
   "source": [
    "## Banknote Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b28b463",
   "metadata": {},
   "source": [
    "The dataset contains 1,372 rows with 5 numeric variables. It is a classification problem with two classes (binary classification).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c37a7f5",
   "metadata": {},
   "source": [
    "Below provides a list of the five variables in the dataset.\n",
    "\n",
    "- variance of Wavelet Transformed image (continuous).\n",
    "- skewness of Wavelet Transformed image (continuous).\n",
    "- kurtosis of Wavelet Transformed image (continuous).\n",
    "- entropy of image (continuous).\n",
    "- class (integer).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ab31502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt\",header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "42198c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns=['variance','skewness','kurtosis','entropy','class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1bdc2f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness  kurtosis  entropy  class\n",
       "0      3.62160   8.66610   -2.8073 -0.44699      0\n",
       "1      4.54590   8.16740   -2.4586 -1.46210      0\n",
       "2      3.86600  -2.63830    1.9242  0.10645      0\n",
       "3      3.45660   9.52280   -4.0112 -3.59440      0\n",
       "4      0.32924  -4.45520    4.5718 -0.98880      0\n",
       "...        ...       ...       ...      ...    ...\n",
       "1367   0.40614   1.34920   -1.4501 -0.55949      1\n",
       "1368  -1.38870  -4.87730    6.4774  0.34179      1\n",
       "1369  -3.75030 -13.45860   17.5932 -2.77710      1\n",
       "1370  -3.56370  -8.38270   12.3930 -1.28230      1\n",
       "1371  -2.54190  -0.65804    2.6842  1.19520      1\n",
       "\n",
       "[1372 rows x 5 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "60228240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(temp):\n",
    "    \"\"\"Calculate the Gini Impurity for a dataframe.\n",
    "    There are a few different ways to do this, I thought this one was\n",
    "    the most concise. See:\n",
    "    https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity\n",
    "    \"\"\"\n",
    "    counts = temp['class'].value_counts().to_dict()\n",
    "    impurity = 1\n",
    "    for lbl in counts:\n",
    "        prob_of_lbl = counts[lbl] / float(len(temp))\n",
    "        impurity -= prob_of_lbl**2\n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "98373012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49386310125882926"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6c6dd1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(left, right, current_uncertainty):\n",
    "    \"\"\"Information Gain.\n",
    "\n",
    "    The uncertainty of the starting node, minus the weighted impurity of\n",
    "    two child nodes.\n",
    "    \"\"\"\n",
    "    fraction = float(len(left)) / (len(left) + len(right))\n",
    "    return current_uncertainty - fraction * gini(left) - (1 - fraction) * gini(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "93fafea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question:\n",
    "    \"\"\"A Question is used to partition a dataset.\n",
    "\n",
    "    This class just records a 'column Name' (e.g., company for company) and a\n",
    "    'column value' (e.g., google). The 'match' method is used to compare\n",
    "    the feature value in an example to the feature value stored in the\n",
    "    question.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "\n",
    "    def match(self, example):\n",
    "        # This has been used to filter out dataframes based on a question\n",
    "        val = example[self.column]\n",
    "        if is_numeric(self.value):\n",
    "            return val >= self.value\n",
    "        else:\n",
    "            return val == self.value\n",
    "\n",
    "    def __repr__(self):\n",
    "        # This is just a helper method to print\n",
    "        # the question in a readable format.\n",
    "        condition = \"==\"\n",
    "        if is_numeric(self.value):\n",
    "            condition = \">=\"\n",
    "        return \"Is %s %s %s?\" % (self.column, condition, str(self.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8ed9f2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1372.000000\n",
       "mean        0.433735\n",
       "std         2.842763\n",
       "min        -7.042100\n",
       "25%        -1.773000\n",
       "50%         0.496180\n",
       "75%         2.821475\n",
       "max         6.824800\n",
       "Name: variance, dtype: float64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['variance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7a3a467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_numeric(value):\n",
    "    \"\"\"Test if a value is numeric.\"\"\"\n",
    "    return isinstance(value, int) or isinstance(value, float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "15a7f831",
   "metadata": {},
   "outputs": [],
   "source": [
    "q=Question('variance',0.433735)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0a854f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'variance'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "21548f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.433735"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "299ba556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.6216</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.446990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.5459</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.462100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.8660</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.106450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.4566</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.594400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.3684</td>\n",
       "      <td>9.67180</td>\n",
       "      <td>-3.9606</td>\n",
       "      <td>-3.162500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>1.3451</td>\n",
       "      <td>0.23589</td>\n",
       "      <td>-1.8785</td>\n",
       "      <td>1.325800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>2.2279</td>\n",
       "      <td>4.09510</td>\n",
       "      <td>-4.8037</td>\n",
       "      <td>-2.111200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>1.2572</td>\n",
       "      <td>4.87310</td>\n",
       "      <td>-5.2861</td>\n",
       "      <td>-5.874100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>1.3183</td>\n",
       "      <td>1.90170</td>\n",
       "      <td>-3.3111</td>\n",
       "      <td>0.065071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>1.4896</td>\n",
       "      <td>3.42880</td>\n",
       "      <td>-4.0309</td>\n",
       "      <td>-1.425900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>692 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness  kurtosis   entropy  class\n",
       "0       3.6216   8.66610   -2.8073 -0.446990      0\n",
       "1       4.5459   8.16740   -2.4586 -1.462100      0\n",
       "2       3.8660  -2.63830    1.9242  0.106450      0\n",
       "3       3.4566   9.52280   -4.0112 -3.594400      0\n",
       "5       4.3684   9.67180   -3.9606 -3.162500      0\n",
       "...        ...       ...       ...       ...    ...\n",
       "1344    1.3451   0.23589   -1.8785  1.325800      1\n",
       "1345    2.2279   4.09510   -4.8037 -2.111200      1\n",
       "1346    1.2572   4.87310   -5.2861 -5.874100      1\n",
       "1351    1.3183   1.90170   -3.3111  0.065071      1\n",
       "1352    1.4896   3.42880   -4.0309 -1.425900      1\n",
       "\n",
       "[692 rows x 5 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[q.column]>=q.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3f230942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_counts(df):\n",
    "    \"\"\"Counts the number of each type of example in a dataset.\"\"\"\n",
    "    return df['class'].value_counts().to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8d334b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 762, 1: 610}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "758067bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.6216</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.446990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.5459</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.462100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.8660</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.106450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.4566</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.594400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.3684</td>\n",
       "      <td>9.67180</td>\n",
       "      <td>-3.9606</td>\n",
       "      <td>-3.162500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>1.3451</td>\n",
       "      <td>0.23589</td>\n",
       "      <td>-1.8785</td>\n",
       "      <td>1.325800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>2.2279</td>\n",
       "      <td>4.09510</td>\n",
       "      <td>-4.8037</td>\n",
       "      <td>-2.111200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>1.2572</td>\n",
       "      <td>4.87310</td>\n",
       "      <td>-5.2861</td>\n",
       "      <td>-5.874100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>1.3183</td>\n",
       "      <td>1.90170</td>\n",
       "      <td>-3.3111</td>\n",
       "      <td>0.065071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>1.4896</td>\n",
       "      <td>3.42880</td>\n",
       "      <td>-4.0309</td>\n",
       "      <td>-1.425900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>692 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness  kurtosis   entropy  class\n",
       "0       3.6216   8.66610   -2.8073 -0.446990      0\n",
       "1       4.5459   8.16740   -2.4586 -1.462100      0\n",
       "2       3.8660  -2.63830    1.9242  0.106450      0\n",
       "3       3.4566   9.52280   -4.0112 -3.594400      0\n",
       "5       4.3684   9.67180   -3.9606 -3.162500      0\n",
       "...        ...       ...       ...       ...    ...\n",
       "1344    1.3451   0.23589   -1.8785  1.325800      1\n",
       "1345    2.2279   4.09510   -4.8037 -2.111200      1\n",
       "1346    1.2572   4.87310   -5.2861 -5.874100      1\n",
       "1351    1.3183   1.90170   -3.3111  0.065071      1\n",
       "1352    1.4896   3.42880   -4.0309 -1.425900      1\n",
       "\n",
       "[692 rows x 5 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[q.match(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b8171057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(temp, question):\n",
    "    \"\"\"Partitions a dataset.\n",
    "    \"\"\"\n",
    "    return temp[question.match(temp)], temp[question.match(temp)==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "63218e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(left, right, current_uncertainty):\n",
    "    \"\"\"Information Gain.\n",
    "\n",
    "    The uncertainty of the starting node, minus the weighted impurity of\n",
    "    two child nodes.\n",
    "    \"\"\"\n",
    "    fraction = float(len(left)) / (len(left) + len(right))\n",
    "    return current_uncertainty - fraction * gini(left) - (1 - fraction) * gini(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "07586148",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_uncertainty = gini(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9e9c7d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1570514220030863"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_rows, false_rows = partition(data, Question('variance', -1.57680))\n",
    "info_gain(true_rows, false_rows, current_uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3befc77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.0421    , -6.9020303 , -6.76196061, -6.62189091, -6.48182121,\n",
       "       -6.34175152, -6.20168182, -6.06161212, -5.92154242, -5.78147273,\n",
       "       -5.64140303, -5.50133333, -5.36126364, -5.22119394, -5.08112424,\n",
       "       -4.94105455, -4.80098485, -4.66091515, -4.52084545, -4.38077576,\n",
       "       -4.24070606, -4.10063636, -3.96056667, -3.82049697, -3.68042727,\n",
       "       -3.54035758, -3.40028788, -3.26021818, -3.12014848, -2.98007879,\n",
       "       -2.84000909, -2.69993939, -2.5598697 , -2.4198    , -2.2797303 ,\n",
       "       -2.13966061, -1.99959091, -1.85952121, -1.71945152, -1.57938182,\n",
       "       -1.43931212, -1.29924242, -1.15917273, -1.01910303, -0.87903333,\n",
       "       -0.73896364, -0.59889394, -0.45882424, -0.31875455, -0.17868485,\n",
       "       -0.03861515,  0.10145455,  0.24152424,  0.38159394,  0.52166364,\n",
       "        0.66173333,  0.80180303,  0.94187273,  1.08194242,  1.22201212,\n",
       "        1.36208182,  1.50215152,  1.64222121,  1.78229091,  1.92236061,\n",
       "        2.0624303 ,  2.2025    ,  2.3425697 ,  2.48263939,  2.62270909,\n",
       "        2.76277879,  2.90284848,  3.04291818,  3.18298788,  3.32305758,\n",
       "        3.46312727,  3.60319697,  3.74326667,  3.88333636,  4.02340606,\n",
       "        4.16347576,  4.30354545,  4.44361515,  4.58368485,  4.72375455,\n",
       "        4.86382424,  5.00389394,  5.14396364,  5.28403333,  5.42410303,\n",
       "        5.56417273,  5.70424242,  5.84431212,  5.98438182,  6.12445152,\n",
       "        6.26452121,  6.40459091,  6.54466061,  6.6847303 ,  6.8248    ])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.linspace(data['variance'].min(),data['variance'].max(),100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "45218e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.0421    , -6.223848  , -5.298302  , -4.842158  , -4.397516  ,\n",
       "       -4.14515   , -3.938136  , -3.80536   , -3.599364  , -3.500423  ,\n",
       "       -3.30979   , -3.08888   , -2.957672  , -2.791262  , -2.665116  ,\n",
       "       -2.57345   , -2.48382   , -2.411395  , -2.322562  , -2.259887  ,\n",
       "       -2.17636   , -2.075445  , -1.997246  , -1.906914  , -1.838576  ,\n",
       "       -1.773     , -1.710262  , -1.649224  , -1.557788  , -1.459496  ,\n",
       "       -1.39701   , -1.3       , -1.237488  , -1.089456  , -0.9604942 ,\n",
       "       -0.880021  , -0.7868944 , -0.7132471 , -0.6205582 , -0.5087397 ,\n",
       "       -0.404088  , -0.3036886 , -0.2340172 , -0.1239716 , -0.02178476,\n",
       "        0.04898145,  0.160401  ,  0.2455717 ,  0.3248208 ,  0.3798    ,\n",
       "        0.49618   ,  0.5488641 ,  0.5975572 ,  0.6732323 ,  0.7532152 ,\n",
       "        0.856054  ,  0.9109708 ,  0.967456  ,  1.06397   ,  1.16378   ,\n",
       "        1.273     ,  1.353164  ,  1.507744  ,  1.587716  ,  1.710636  ,\n",
       "        1.812765  ,  1.908946  ,  2.010116  ,  2.093896  ,  2.194795  ,\n",
       "        2.29175   ,  2.42083   ,  2.533532  ,  2.613388  ,  2.70621   ,\n",
       "        2.821475  ,  2.941348  ,  3.053333  ,  3.189042  ,  3.270526  ,\n",
       "        3.42152   ,  3.479079  ,  3.53756   ,  3.621355  ,  3.740832  ,\n",
       "        3.80244   ,  3.883248  ,  3.930632  ,  3.983296  ,  4.046006  ,\n",
       "        4.11793   ,  4.18607   ,  4.281264  ,  4.394096  ,  4.593418  ,\n",
       "        4.714415  ,  4.92514   ,  5.059555  ,  5.269888  ,  5.693093  ,\n",
       "        6.8248    ,  6.8248    ])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9888fa97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0., 100., 200., 300., 400., 500., 600., 700., 800., 900.])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0,900,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "41dc3780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1bc72817",
   "metadata": {},
   "outputs": [],
   "source": [
    "gain,ques=find_best_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "428338ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_rows,false_rows=partition(data,ques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8b62041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    \"\"\"A Leaf node classifies data.\n",
    "\n",
    "    This holds a dictionary of class (e.g., \"Apple\") -> number of times\n",
    "    it appears in the rows from the training data that reach this leaf.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.predictions = class_counts(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e732dd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_Node:\n",
    "    \"\"\"A Decision Node asks a question.\n",
    "\n",
    "    This holds a reference to the question, and to the two child nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 question,\n",
    "                 true_branch,\n",
    "                 false_branch):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "65c6308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(rows):\n",
    "    \"\"\"Builds the tree.\n",
    "\n",
    "    Rules of recursion: 1) Believe that it works. 2) Start by checking\n",
    "    for the base case (no further information gain). 3) Prepare for\n",
    "    giant stack traces.\n",
    "    \"\"\"\n",
    "\n",
    "    # Try partitioing the dataset on each of the unique attribute,\n",
    "    # calculate the information gain,\n",
    "    # and return the question that produces the highest gain.\n",
    "    gain, question = find_best_split(rows)\n",
    "\n",
    "    # Base case: no further info gain\n",
    "    # Since we can ask no further questions,\n",
    "    # we'll return a leaf.\n",
    "    if gain == 0:\n",
    "        return Leaf(rows)\n",
    "\n",
    "    # If we reach here, we have found a useful feature / value\n",
    "    # to partition on.\n",
    "    true_rows, false_rows = partition(rows, question)\n",
    "\n",
    "    # Recursively build the true branch.\n",
    "    true_branch = build_tree(true_rows)\n",
    "\n",
    "    # Recursively build the false branch.\n",
    "    false_branch = build_tree(false_rows)\n",
    "\n",
    "    # Return a Question node.\n",
    "    # This records the best feature / value to ask at this point,\n",
    "    # as well as the branches to follow\n",
    "    # dependingo on the answer.\n",
    "    return Decision_Node(question, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "42306097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, spacing=\"\"):\n",
    "    \"\"\"World's most elegant tree printing function.\"\"\"\n",
    "\n",
    "    # Base case: we've reached a leaf\n",
    "    if isinstance(node, Leaf):\n",
    "        print (spacing + \"Predict\", node.predictions)\n",
    "        return\n",
    "\n",
    "    # Print the question at this node\n",
    "    print (spacing + str(node.question))\n",
    "\n",
    "    # Call this function recursively on the true branch\n",
    "    print (spacing + '--> True:')\n",
    "    print_tree(node.true_branch, spacing + \"  \")\n",
    "\n",
    "    # Call this function recursively on the false branch\n",
    "    print (spacing + '--> False:')\n",
    "    print_tree(node.false_branch, spacing + \"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "af8e32bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(df):\n",
    "    \"\"\"Find the best question to ask by iterating over every feature / value\n",
    "    and calculating the information gain.\"\"\"\n",
    "    best_gain = 0  # keep track of the best information gain\n",
    "    best_question = None  # keep train of the feature / value that produced it\n",
    "    current_uncertainty = gini(df)\n",
    "    n_features = len(df.columns) - 1  # number of columns\n",
    "\n",
    "    for col in df.columns[:-1]:  # for each feature\n",
    "        if(is_numeric(df[col].iloc[0])):\n",
    "            # For values equally spaced on the number line\n",
    "            values=np.linspace(data['variance'].min(),data['variance'].max(),50)\n",
    "            # For percentiles\n",
    "            #values=data[col].describe(percentiles=[x/100 for x in range(101)]).values[10:60]\n",
    "            \n",
    "            #values = df[col].unique()  # unique values in the column\n",
    "        else:\n",
    "            values = df[col].unique()  # unique values in the column\n",
    "\n",
    "        for val in values:  # for each value\n",
    "\n",
    "            question = Question(col, val)\n",
    "\n",
    "            # try splitting the dataset\n",
    "            true_rows, false_rows = partition(df, question)\n",
    "\n",
    "            # Skip this split if it doesn't divide the\n",
    "            # dataset.\n",
    "            if len(true_rows) == 0 or len(false_rows) == 0:\n",
    "                continue\n",
    "\n",
    "            # Calculate the information gain from this split\n",
    "            gain = info_gain(true_rows, false_rows, current_uncertainty)\n",
    "\n",
    "            # You actually can use '>' instead of '>=' here\n",
    "            # but I wanted the tree to look a certain way for our\n",
    "            # toy dataset.\n",
    "            if gain >= best_gain:\n",
    "                best_gain, best_question = gain, question\n",
    "\n",
    "    return best_gain, best_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "800b0ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken= 40.765543937683105\n"
     ]
    }
   ],
   "source": [
    "import time as tm\n",
    "start=tm.time()\n",
    "my_tree = build_tree(data)\n",
    "end=tm.time()\n",
    "print(\"time taken=\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f7a5f1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken= 7.1651930809021\n"
     ]
    }
   ],
   "source": [
    "import time as tm\n",
    "start=tm.time()\n",
    "my_tree = build_tree(data)\n",
    "end=tm.time()\n",
    "print(\"time taken=\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c53b3e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(row, node):\n",
    "    \"\"\"See the 'rules of recursion' above.\"\"\"\n",
    "\n",
    "    # Base case: we've reached a leaf\n",
    "    if isinstance(node, Leaf):\n",
    "        return node.predictions\n",
    "\n",
    "    # Decide whether to follow the true-branch or the false-branch.\n",
    "    # Compare the feature / value stored in the node,\n",
    "    # to the example we're considering.\n",
    "    if node.question.match(row):\n",
    "        return classify(row, node.true_branch)\n",
    "    else:\n",
    "        return classify(row, node.false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "97a149d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 433}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(data.iloc[0], my_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c0cb0733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_leaf(counts):\n",
    "    \"\"\"A nicer way to print the predictions at a leaf.\"\"\"\n",
    "    total = sum(counts.values()) * 1.0\n",
    "    probs = {}\n",
    "    for lbl in counts.keys():\n",
    "        probs[lbl] = str(int(counts[lbl] / total * 100)) + \"%\"\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "05b9a125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 0.0. Predicted: 0\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n",
      "Actual: 1.0. Predicted: 1\n"
     ]
    }
   ],
   "source": [
    "for index,row in data.iterrows():\n",
    "    d = classify(row, my_tree)\n",
    "    Keymax = max(zip(d.values(), d.keys()))[1]\n",
    "    print (\"Actual: %s. Predicted: %s\" % (row['class'], Keymax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e31d0bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is variance >= 0.3223?\n",
      "--> True:\n",
      "  Is kurtosis >= -4.3839?\n",
      "  --> True:\n",
      "    Is variance >= 1.594?\n",
      "    --> True:\n",
      "      Is variance >= 2.0421?\n",
      "      --> True:\n",
      "        Predict {0: 433}\n",
      "      --> False:\n",
      "        Is kurtosis >= -2.3386?\n",
      "        --> True:\n",
      "          Predict {0: 52}\n",
      "        --> False:\n",
      "          Is entropy >= -1.7207?\n",
      "          --> True:\n",
      "            Predict {1: 3}\n",
      "          --> False:\n",
      "            Predict {0: 1}\n",
      "    --> False:\n",
      "      Is kurtosis >= -2.2718?\n",
      "      --> True:\n",
      "        Is entropy >= 0.097399?\n",
      "        --> True:\n",
      "          Is kurtosis >= 2.0013?\n",
      "          --> True:\n",
      "            Predict {0: 18}\n",
      "          --> False:\n",
      "            Is skewness >= 6.1189?\n",
      "            --> True:\n",
      "              Predict {0: 2}\n",
      "            --> False:\n",
      "              Predict {1: 17}\n",
      "        --> False:\n",
      "          Is variance >= 0.4339?\n",
      "          --> True:\n",
      "            Predict {0: 103}\n",
      "          --> False:\n",
      "            Is kurtosis >= -1.1982?\n",
      "            --> True:\n",
      "              Predict {0: 16}\n",
      "            --> False:\n",
      "              Predict {1: 1}\n",
      "      --> False:\n",
      "        Is skewness >= 7.6377?\n",
      "        --> True:\n",
      "          Predict {0: 3}\n",
      "        --> False:\n",
      "          Predict {1: 24}\n",
      "  --> False:\n",
      "    Is skewness >= 9.1814?\n",
      "    --> True:\n",
      "      Predict {0: 10}\n",
      "    --> False:\n",
      "      Predict {1: 32}\n",
      "--> False:\n",
      "  Is skewness >= 7.6274?\n",
      "  --> True:\n",
      "    Is variance >= -4.2859?\n",
      "    --> True:\n",
      "      Predict {0: 85}\n",
      "    --> False:\n",
      "      Predict {1: 20}\n",
      "  --> False:\n",
      "    Is variance >= -0.39816?\n",
      "    --> True:\n",
      "      Is skewness >= 5.8974?\n",
      "      --> True:\n",
      "        Predict {0: 11}\n",
      "      --> False:\n",
      "        Is kurtosis >= 3.1143?\n",
      "        --> True:\n",
      "          Is entropy >= 1.547?\n",
      "          --> True:\n",
      "            Predict {1: 1}\n",
      "          --> False:\n",
      "            Predict {0: 11}\n",
      "        --> False:\n",
      "          Predict {1: 58}\n",
      "    --> False:\n",
      "      Is kurtosis >= 6.2204?\n",
      "      --> True:\n",
      "        Is skewness >= -4.6062?\n",
      "        --> True:\n",
      "          Is kurtosis >= 6.7756?\n",
      "          --> True:\n",
      "            Predict {0: 15}\n",
      "          --> False:\n",
      "            Is entropy >= -0.056479?\n",
      "            --> True:\n",
      "              Predict {1: 1}\n",
      "            --> False:\n",
      "              Predict {0: 1}\n",
      "        --> False:\n",
      "          Predict {1: 130}\n",
      "      --> False:\n",
      "        Is skewness >= 7.3273?\n",
      "        --> True:\n",
      "          Is entropy >= -1.4543?\n",
      "          --> True:\n",
      "            Predict {0: 1}\n",
      "          --> False:\n",
      "            Predict {1: 3}\n",
      "        --> False:\n",
      "          Predict {1: 320}\n"
     ]
    }
   ],
   "source": [
    "print_tree(my_tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb459451",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b7ecfa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.DataFrame([x.split(\"\\t\") for x in \"\"\"Lemon\t1\n",
    "Lemon\t1.2\n",
    "Lemon\t1.3\n",
    "Lemon\t1.4\n",
    "Lemon\t1.5\n",
    "Lemon\t1.6\n",
    "Orange\t1.7\n",
    "Orange\t1.8\n",
    "Orange\t1.9\n",
    "Orange\t2\n",
    "Orange\t2.1\n",
    "Orange\t2.2\n",
    "Orange\t2.3\n",
    "Orange\t2.4\"\"\".split(\"\\n\")],columns=['Label','Diameter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "64a85de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['y']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0b78c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['Diameter']=temp['Diameter'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c40fa0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lemon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lemon</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lemon</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lemon</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lemon</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lemon</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Orange</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Orange</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Orange</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Orange</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Orange</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Orange</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Orange</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Orange</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label  Diameter  y\n",
       "0    Lemon       1.0  0\n",
       "1    Lemon       1.2  0\n",
       "2    Lemon       1.3  0\n",
       "3    Lemon       1.4  0\n",
       "4    Lemon       1.5  0\n",
       "5    Lemon       1.6  0\n",
       "6   Orange       1.7  0\n",
       "7   Orange       1.8  0\n",
       "8   Orange       1.9  0\n",
       "9   Orange       2.0  0\n",
       "10  Orange       2.1  0\n",
       "11  Orange       2.2  0\n",
       "12  Orange       2.3  0\n",
       "13  Orange       2.4  0"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d50fbf66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Diameter', ylabel='y'>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x='Diameter',y='y',hue='Label',data=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef7f221",
   "metadata": {},
   "source": [
    "### What is a Support Vector Machine?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fe4160",
   "metadata": {},
   "source": [
    "Support Vector Machine(SVM) is a supervised machine learning algorithm used for both classification and regression. Although its best suited for classification. The objective of SVM algorithm is to find a hyperplane in an N-dimensional space that distinctly classifies the data points. The dimension of the hyperplane depends upon the number of features. If the number of input features is two, then the hyperplane is just a line. If the number of input features is three, then the hyperplane becomes a 2-D plane. It becomes difficult to imagine when the number of features exceeds three. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f870ca0",
   "metadata": {},
   "source": [
    "Out of infinite possible hyperplanes the best possible hyperplane the best hyper plane is chosen based on maximum distances between the two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd78117",
   "metadata": {},
   "source": [
    "## Effect of outliers in SVM to be discussed while maths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31abb0be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57e8759a",
   "metadata": {},
   "source": [
    "### When to use logistic regression vs Support vector machine?\n",
    "\n",
    "SVM works best when the dataset is small and complex i.e. when there is possibility of overfitting in logistics regression. It is usually advisable to first use logistic regression and see how does it performs, if it fails to give a good accuracy you can go for SVM without any kernel. Logistic regression and SVM without any kernel have similar performance but depending on your features, one may be more efficient than the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73cbbf1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Types of Support Vector Machine\n",
    "#### Linear SVM\n",
    "When the data is perfectly linearly separable only then we can use Linear SVM. Perfectly linearly separable means that the data points can be classified into 2 classes by using a single straight line(if 2D).\n",
    "\n",
    "#### Non-Linear SVM\n",
    "When the data is not linearly separable then we can use Non-Linear SVM, which means when the data points cannot be separated into 2 classes by using a straight line (if 2D) then we use some advanced techniques like kernel tricks to classify them. In most real-world applications we do not find linearly separable datapoints hence we use kernel trick to solve them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7e78b8",
   "metadata": {},
   "source": [
    "# Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde02d98",
   "metadata": {},
   "source": [
    "<b>Support Vectors:</b> These are the points that are closest to the hyperplane. A separating line will be defined with the help of these data points.\n",
    "\n",
    "<b>Margin:</b> it is the distance between the hyperplane and the observations closest to the hyperplane (support vectors). In SVM large margin is considered a good margin. There are two types of margins hard margin and soft margin. I will talk more about these two in the later section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9d34b0",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://miro.medium.com/proxy/0*KYsgeNVhnm_ASBoM.png\" width=\"800\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b096182",
   "metadata": {},
   "source": [
    "\n",
    "### How does Support Vector Machine work?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc26d8c2",
   "metadata": {},
   "source": [
    "SVM is defined such that it is defined in terms of the support vectors only, we don’t have to worry about other observations since the margin is made using the points which are closest to the hyperplane (support vectors), whereas in logistic regression the classifier is defined over all the points. Hence SVM enjoys some natural speed-ups.\n",
    "Let’s understand the working of SVM using an example. Suppose we have a dataset that has two classes (green and blue). We want to classify that the new data point as either blue or green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "18dc2aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame()\n",
    "x=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]\n",
    "y1=[7,5,9,6,10,7,5,12,8,4,7,5,8,9,11,7,4,18]\n",
    "label=['blue','blue','blue','blue','blue','blue','blue','blue','blue','red','red','red','red','red','red','red','red','red']\n",
    "data['x']=x\n",
    "data['y']=y1\n",
    "data['label']=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f6fadb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e037125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "adc56ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "#plt.scatter(np.array(range(100)), np.array([f(x) for x in range(100)]),  color='black')\n",
    "sns.scatterplot(x='x',y='y',hue='label',data=data,s=100)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Entropy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78167987",
   "metadata": {},
   "source": [
    "To classify these points, we can have many decision boundaries, but the question is which is the best and how do we find it? NOTE: Since we are plotting the data points in a 2-dimensional graph we call this decision boundary a straight line but if we have more dimensions, we call this decision boundary a “hyperplane”\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af81ad3",
   "metadata": {},
   "source": [
    "The best hyperplane is that plane that has the maximum distance from both the classes, and this is the main aim of SVM. This is done by finding different hyperplanes which classify the labels in the best way then it will choose the one which is farthest from the data points or the one which has a maximum margin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05998be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7839321",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Mathematical Intuition behind Support Vector Machine\n",
    "Many people skip the math intuition behind this algorithm because it is pretty hard to digest. Here in this section, we’ll try to understand each and every step working under the hood. SVM is a broad topic and people are still doing research on this algorithm. If you are planning to do research, then this might not be the right place for you.\n",
    "\n",
    "Here we will understand only that part that is required in implementing this algorithm. You must have heard about the primal formulation, dual formulation, Lagranges multiplier etc. I am not saying these topics aren’t important, but they are more important if you are planning to do research in this area. Let’s move ahead and see the magic behind this algorithm.\n",
    "\n",
    "Before getting into the nitty-gritty details of this topic first let’s understand what a dot product is.\n",
    "\n",
    "#### Dot-Product\n",
    "\n",
    "\n",
    "#### Use of Dot Product in SVM:\n",
    "\n",
    "\n",
    "#### Margin in Support Vector Machine\n",
    "\n",
    "\n",
    "### Optimization function and its constraints\n",
    "\n",
    "\n",
    "\n",
    "### Soft Margin SVM\n",
    "\n",
    "\n",
    "### Kernels in Support Vector Machine\n",
    "\n",
    "\n",
    "### Different Kernel functions\n",
    "\n",
    "\n",
    "- Polynomial kernel\n",
    "- Sigmoid kernel\n",
    "- RBF kernel\n",
    "- Bessel function kernel\n",
    "- Anova Kernel\n",
    "\n",
    "### How to choose the right Kernel? \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662af80a",
   "metadata": {},
   "source": [
    "### Implementation and hyperparameter tuning of Support Vector Machine in Python \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0b3bd557",
   "metadata": {},
   "outputs": [],
   "source": [
    "link='https://raw.githubusercontent.com/robintux/Datasets4StackOverFlowQuestions/master/income_evaluation.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c21c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab86008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
